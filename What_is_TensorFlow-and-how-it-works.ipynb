{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) More basic than basic of TensorFlow\n",
    "\n",
    "To use tf lunch this notebook from docker.\n",
    "\n",
    "Initialize docker.\n",
    "\n",
    "Start the container\n",
    "\n",
    "- `docker start -a coursera-aml-2`\n",
    "\n",
    "To stop the container, in a different terminal window\n",
    "\n",
    "- `docker stop -a coursera-aml-2`\n",
    "\n",
    "Tf must be lunched after the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Let us initialize a graph for something as simple as multiplying and adding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "# Because if one runs something (e.g. a placeholder) several time,\n",
    "# use this reset to avoid graph to be cluttered\n",
    "\n",
    "a = tf.placeholder(np.float32, (2, 2)) # For defining a tensor to be filled\n",
    "b = tf.Variable(tf.ones((2, 2))) # Define a Variable\n",
    "ct = tf.constant(np.ones((2,2)), dtype=tf.float32)\n",
    "\n",
    "c = a @ b + ct # Multimplied both tensors and sum a constant tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession() \n",
    "# To run the graph we need a session object that encapsulates \n",
    "# the environment where operations are exectued and tensor objects \n",
    "# are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  3.],\n",
       "       [ 3.,  3.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.run(tf.global_variables_initializer()) # compute initial values in graph execution environment \n",
    "s.run(c, feed_dict={a: np.ones((2, 2))}) # Feed the placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close() # Release resources for the session when not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is tf doing?\n",
    "\n",
    "Every node in the graph is an operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'Placeholder' type=Placeholder>,\n",
       " <tf.Operation 'ones' type=Const>,\n",
       " <tf.Operation 'Variable' type=VariableV2>,\n",
       " <tf.Operation 'Variable/Assign' type=Assign>,\n",
       " <tf.Operation 'Variable/read' type=Identity>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'matmul' type=MatMul>,\n",
       " <tf.Operation 'add' type=Add>,\n",
       " <tf.Operation 'init' type=NoOp>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()\n",
    "# If we do not use tf.reset_default_graph(), it will create \n",
    "# a placeholder each time we run the cell and the graph will be \n",
    "# effectively cluttered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what tf is doing for each node.\n",
    "\n",
    "The output tensor of each operation is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'Placeholder:0' shape=(2, 2) dtype=float32>]\n",
      "[<tf.Tensor 'ones:0' shape=(2, 2) dtype=float32>]\n",
      "[<tf.Tensor 'Variable:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[<tf.Tensor 'Variable/Assign:0' shape=(2, 2) dtype=float32_ref>]\n",
      "[<tf.Tensor 'Variable/read:0' shape=(2, 2) dtype=float32>]\n",
      "[<tf.Tensor 'Const:0' shape=(2, 2) dtype=float32>]\n",
      "[<tf.Tensor 'matmul:0' shape=(2, 2) dtype=float32>]\n",
      "[<tf.Tensor 'add:0' shape=(2, 2) dtype=float32>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.get_default_graph().get_operations()[0].outputs) # define placeholder\n",
    "print(tf.get_default_graph().get_operations()[1].outputs) # define a tensor of 1's\n",
    "print(tf.get_default_graph().get_operations()[2].outputs) # define tensor Variable\n",
    "print(tf.get_default_graph().get_operations()[3].outputs) # assign Variable op.\n",
    "print(tf.get_default_graph().get_operations()[4].outputs) # read Variable op.\n",
    "print(tf.get_default_graph().get_operations()[5].outputs) # define constant ct\n",
    "print(tf.get_default_graph().get_operations()[6].outputs) # multiplication op.\n",
    "print(tf.get_default_graph().get_operations()[7].outputs) # addition\n",
    "print(tf.get_default_graph().get_operations()[8].outputs) # init op."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Let us just multiply two scalars as placeholders, feed them with data and see the operations in each node of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Create a placeholder data a\n",
    "a = tf.placeholder(tf.float32, name=\"input1\") \n",
    "# Create a placeholder data b\n",
    "b = tf.placeholder(tf.float32, name=\"input2\") \n",
    "# Create an multiply operation using a and b\n",
    "c = tf.multiply(a, b, name=\"multiply_op\")\n",
    "s = tf.Session()\n",
    "feed_dict = {a: 3.0, b: 2.0}\n",
    "output = s.run(c, feed_dict)\n",
    "print (output)\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Numbers can be multiplied just as constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mul:0\", shape=(), dtype=float32)\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "a = tf.constant(5.0)\n",
    "b = tf.constant(6.0)\n",
    "c = a * b\n",
    "s = tf.InteractiveSession() # To run the graph\n",
    "print(c)\n",
    "print(s.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.run(c)\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) A first basic model in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Simple optimization (with prints in jupiyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.get_variable(\"x\", shape=(), dtype=tf.float32#, trainable=True\n",
    "                   )\n",
    "# define scalar Variable x that can be updated during execution.\n",
    "# All variables are trainable by default! If trainable=False variable \n",
    "# will not be updated during backpropagation\n",
    "f = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x/Initializer/random_uniform/shape' type=Const>,\n",
       " <tf.Operation 'x/Initializer/random_uniform/min' type=Const>,\n",
       " <tf.Operation 'x/Initializer/random_uniform/max' type=Const>,\n",
       " <tf.Operation 'x/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
       " <tf.Operation 'x/Initializer/random_uniform/sub' type=Sub>,\n",
       " <tf.Operation 'x/Initializer/random_uniform/mul' type=Mul>,\n",
       " <tf.Operation 'x/Initializer/random_uniform' type=Add>,\n",
       " <tf.Operation 'x' type=VariableV2>,\n",
       " <tf.Operation 'x/Assign' type=Assign>,\n",
       " <tf.Operation 'x/read' type=Identity>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimization of $f$ w.r.t. $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1) # 0.1 is the learning rate \n",
    "step = optimizer.minimize(f#, var_list=[x]\n",
    "                         )\n",
    "# minimize gives operation that can be run as many times as one wishes.\n",
    "# As Variables are trainable by default, one has not to sprecify them:\n",
    "# We can omit var_list=[x], but one can put trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'x:0' shape=() dtype=float32_ref>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables() # get trainable variables, i.g. x (scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make 10 gradient descent steps with a Python loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.538244 0.452667\n",
      "-0.430595 0.289707\n",
      "-0.344476 0.185412\n",
      "-0.275581 0.118664\n",
      "-0.220465 0.075945\n",
      "-0.176372 0.0486048\n",
      "-0.141098 0.0311071\n",
      "-0.112878 0.0199085\n",
      "-0.0903024 0.0127414\n",
      "-0.0722419 0.00815453\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:  # in this way session will be closed automatically\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        _, curr_x, curr_f = s.run([step, x, f]) # \"_\": Ignore values when unpacking\n",
    "        print(curr_x, curr_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both $f$ and $x$ goes to Zero, but the values are not synchronized because the order of opperations is not fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Simple optimization (with tf.Print for synchronized output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.get_variable(\"x\", shape=(), dtype=tf.float32)\n",
    "f = x ** 2\n",
    "f = tf.Print(f, [x, f], \"x, f:\") # Prints are redirected to stdout when run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as s:\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        s.run([step, f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints to jupyter server stdout the following synchronized output:\n",
    "\n",
    "x, f:[0.69188243][0.74797076]\n",
    "\n",
    "x, f:[0.69188243][0.47870129]\n",
    "\n",
    "x, f:[0.55350596][0.30636886]\n",
    "\n",
    "x, f:[0.44280475][0.19607605]\n",
    "\n",
    "x, f:[0.35424381][0.12548868]\n",
    "\n",
    "x, f:[0.28339505][0.080312759]\n",
    "\n",
    "x, f:[0.22671604][0.051400162]\n",
    "\n",
    "x, f:[0.18137284][0.032896105]\n",
    "\n",
    "x, f:[0.14509827][0.021053508]\n",
    "\n",
    "x, f:[0.11607862][0.013474245]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Simple optimization (with TensorBoard logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.get_variable(\"x\", shape=(), dtype=tf.float32)\n",
    "f = x ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('curr_x', x)\n",
    "tf.summary.scalar('curr_f', f)\n",
    "summaries = tf.summary.merge_all() # Merge summaries in a single node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "s = tf.InteractiveSession()\n",
    "summary_writer = tf.summary.FileWriter(\"logs/1\", s.graph) \n",
    "# Run number at the end of the path. It will be useful for visualization\n",
    "s.run(tf.global_variables_initializer())\n",
    "for i in range(10):\n",
    "    _, curr_summaries = s.run([step, summaries])\n",
    "    summary_writer.add_summary(curr_summaries, i)\n",
    "    summary_writer.flush()\n",
    "# flush that data on disk so that you see that in a beautiful web interface. \n",
    "# This cell creates tf events in log folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point **TensorBoard** must be lunched\n",
    "\n",
    "Execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'54' at http://0496760811e8:6006\n",
      "(Press CTRL+C to quit)\n",
      "WARNING:tensorflow:Deleting accumulator '4'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run  `tensorboard --logdir=./logs` in bash of Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is displayed in browser\n",
    "<img src=\"TensorBoard.jpg\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III) Solve a linear regrassion\n",
    "\n",
    "### 7) Training a linear model\n",
    "\n",
    "Generate artificial data with liear structure but with some random noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3) (1000, 1)\n",
      "[[ 0.41150911  0.75097625  0.38692369]]\n"
     ]
    }
   ],
   "source": [
    "# model data\n",
    "N = 1000 # with 1000 exaples\n",
    "D = 3    # and 3 features\n",
    "x = np.random.random((N, D))\n",
    "w = np.random.random((D, 1))\n",
    "y = x @ w + np.random.randn(N, 1) * 0.20\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "print(w.T) # traspose of w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations for making **predictions**: \n",
    "- apply a linear model to all instances and store in  `predictions` tensor\n",
    "\n",
    "- define a loss function to optimize parameters (e.g. Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3) (?, 1) (?, 1) ()\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholders for the input data and the target\n",
    "features = tf.placeholder(tf.float32, shape=(None, D))\n",
    "target = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "weights = tf.get_variable(\"weights\", shape=(D, 1), dtype=tf.float32)\n",
    "predictions = features @ weights\n",
    "\n",
    "loss = tf.reduce_mean((target - predictions) ** 2) \n",
    "\n",
    "print(features.shape, target.shape, predictions.shape, loss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run backpropagation an optimizer is needed (e.g. Gradient Descent Optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss every 50 iterations\n",
      "0.361292 [[ 0.72192955  1.15506291  0.57392067]]\n",
      "0.0385988 [[ 0.43164018  0.77441603  0.35024849]]\n",
      "0.0381573 [[ 0.43643445  0.74086052  0.38003212]]\n",
      "0.0380741 [[ 0.4386887   0.72623998  0.39288509]]\n",
      "0.0380584 [[ 0.43973589  0.71986264  0.39842585]]\n",
      "0.0380554 [[ 0.44022036  0.71708065  0.4008145 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    s.run(tf.global_variables_initializer())\n",
    "    print('current loss every 50 iterations')\n",
    "    for i in range(300):\n",
    "        _, curr_loss, curr_weights = s.run([step, loss, weights], \n",
    "                                           feed_dict={features: x, target: y})\n",
    "        if i % 50 == 0:\n",
    "            print(curr_loss, curr_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44044062,  0.71588272,  0.40183106]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# found weights\n",
    "curr_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41150911,  0.75097625,  0.38692369]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true weights\n",
    "w.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 8) Model checkpoints\n",
    "\n",
    "If training process takes a long time, it will benefict from model checkpoints. It can be saved the work, and continue if interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14964\n",
      "0.0500833\n",
      "0.0402815\n",
      "0.038467\n",
      "0.0381311\n",
      "0.0380689\n"
     ]
    }
   ],
   "source": [
    "s = tf.InteractiveSession()\n",
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "s.run(tf.global_variables_initializer())\n",
    "for i in range(300):\n",
    "    _, curr_loss, curr_weights = s.run([step,loss, weights],\n",
    "                                       feed_dict={features: x, target: y})\n",
    "    if i % 50 == 0:\n",
    "        saver.save(s,\"logs/2/model.ckpt\",global_step=i) \n",
    "        # Save trainable_variables in iterations to a desirable lkocation on disk (e.g. logs)\n",
    "        print(curr_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logs/2/model.ckpt-50',\n",
       " 'logs/2/model.ckpt-100',\n",
       " 'logs/2/model.ckpt-150',\n",
       " 'logs/2/model.ckpt-200',\n",
       " 'logs/2/model.ckpt-250']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.last_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve last saved checkpoints with restore method\n",
    "\n",
    "It only contains tensor and vales, then only variables' values are restored. It does not contain graph definitions, therefore one needs to define a graph in the *same way* **before restoring** a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from logs/2/model.ckpt-50\n"
     ]
    }
   ],
   "source": [
    "saver.restore(s,\"logs/2/model.ckpt-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't see now how to continue iterating from there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve a linear regrassion (with TensorBoard logging) --Unfinished--\n",
    "\n",
    "We use the same model data introduced before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "features = tf.placeholder(tf.float32, shape=(None, D))\n",
    "target = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "weights = tf.get_variable(\"weights\", shape=(D, 1), dtype=tf.float32)\n",
    "predictions = features @ weights\n",
    "\n",
    "loss = tf.reduce_mean((target - predictions) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 3) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('curr_features', features[0])\n",
    "tf.summary.scalar('curr_predictions', predictions)\n",
    "summaries = tf.summary.merge_all() # Merge summaries in a single node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current loss every 50 iterations\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "tags and values not the same shape: [] != [1000,3] (tag 'c')\n\t [[Node: c = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](c/tags, _arg_Placeholder_0_0)]]\n\nCaused by op 'c', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-36-b895f756caa4>\", line 1, in <module>\n    tf.summary.scalar('curr_features'[0], features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/summary/summary.py\", line 129, in scalar\n    tags=scope.rstrip('/'), values=tensor, name=scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 265, in _scalar_summary\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): tags and values not the same shape: [] != [1000,3] (tag 'c')\n\t [[Node: c = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](c/tags, _arg_Placeholder_0_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: tags and values not the same shape: [] != [1000,3] (tag 'c')\n\t [[Node: c = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](c/tags, _arg_Placeholder_0_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e11d425236fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         _, curr_summaries, curr_loss, curr_weights = s.run(\n\u001b[1;32m      7\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             feed_dict={features: x, target: y})\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_summaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msummary_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: tags and values not the same shape: [] != [1000,3] (tag 'c')\n\t [[Node: c = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](c/tags, _arg_Placeholder_0_0)]]\n\nCaused by op 'c', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-36-b895f756caa4>\", line 1, in <module>\n    tf.summary.scalar('curr_features'[0], features)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/summary/summary.py\", line 129, in scalar\n    tags=scope.rstrip('/'), values=tensor, name=scope)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 265, in _scalar_summary\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): tags and values not the same shape: [] != [1000,3] (tag 'c')\n\t [[Node: c = ScalarSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](c/tags, _arg_Placeholder_0_0)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    summary_writer = tf.summary.FileWriter(\"logs/3\", s.graph) # Where to store these logs. \n",
    "    s.run(tf.global_variables_initializer())\n",
    "    print('current loss every 50 iterations')\n",
    "    for i in range(300):\n",
    "        _, curr_summaries, curr_loss, curr_weights = s.run(\n",
    "            [step, summaries, loss, weights], \n",
    "            feed_dict={features: x, target: y})\n",
    "        summary_writer.add_summary(curr_summaries, i)\n",
    "        summary_writer.flush()\n",
    "        if i % 50 == 0:\n",
    "            print(curr_loss, curr_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
